{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Conda\\envs\\Tensorflow-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Conda\\envs\\Tensorflow-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Conda\\envs\\Tensorflow-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Conda\\envs\\Tensorflow-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Conda\\envs\\Tensorflow-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Conda\\envs\\Tensorflow-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import LeakyReLU, Conv2D, Conv2DTranspose, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Reshape, Activation\n",
    "from keras.models import Model,Sequential\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "from os import walk\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs  = 50000\n",
    "noise_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with colab:\n",
    "#!unzip pokemon_small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Conda\\envs\\Tensorflow-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16384)             1654784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16384)             65536     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 16, 16, 128)       819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 32, 32, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 64, 64, 3)         4803      \n",
      "=================================================================\n",
      "Total params: 2,750,083\n",
      "Trainable params: 2,716,931\n",
      "Non-trainable params: 33,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------\n",
    "# Define the generator - take noise and convert them to images\n",
    "#------------------------------------------------------------------------------------\n",
    "def generator():\n",
    "    generator=Sequential()\n",
    "    \n",
    "    # output: 8*8*512\n",
    "    generator.add(Dense(8*8*512, input_shape=(noise_size,)))\n",
    "    generator.add(BatchNormalization(momentum=0.9))\n",
    "    generator.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    #output: (8,8,512)\n",
    "    generator.add(Reshape((8, 8, 512)))\n",
    "    generator.add(Dropout(0.5)) \n",
    "   \n",
    "    # output: (8,8,256)\n",
    "    generator.add(Conv2DTranspose(256, kernel_size=(5,5), padding='same'))\n",
    "    generator.add(BatchNormalization(momentum=0.9))\n",
    "    generator.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # output: (16,16,128)\n",
    "    generator.add(Conv2DTranspose(128, strides=(2, 2), kernel_size=(5,5), padding='same'))\n",
    "    generator.add(BatchNormalization(momentum=0.9))\n",
    "    generator.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # output: (32,32,64)\n",
    "    generator.add(Conv2DTranspose(64, strides=(2, 2), kernel_size=(5,5), padding='same'))\n",
    "    generator.add(BatchNormalization(momentum=0.9))\n",
    "    generator.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    # output: (64,64,3)\n",
    "    generator.add(Conv2DTranspose(3, strides=(2, 2), kernel_size=(5,5), padding='same', activation='sigmoid'))\n",
    "    \n",
    "    return generator\n",
    "\n",
    "g=generator()\n",
    "g.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "noise = tf.random.normal([1, 200])\n",
    "print(g(noise)[0].shape)\n",
    "generated = g(noise)[0]\n",
    "print(generated[0,1,0])\n",
    "\n",
    "generated=np.array(generated).reshape((64,64,3))\n",
    "print(generated.dtype)\n",
    "print(generated.shape)\n",
    "plt.imshow(generated[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Conda\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 16385     \n",
      "=================================================================\n",
      "Total params: 1,045,633\n",
      "Trainable params: 1,045,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------------------\n",
    "# Define the Discriminator - take both real images and synthetic fake images \n",
    "# from Generator and classify the real and fake images properly\n",
    "#-------------------------------------------------------------------------------------------\n",
    "def discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[64, 64, 3]))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "d=discriminator()\n",
    "d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_2 (Sequential)    (None, 1)                 1045633   \n",
      "=================================================================\n",
      "Total params: 1,045,633\n",
      "Trainable params: 1,045,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# the trainable discriminator model with binary crossentroy loss and RMS optimizer\n",
    "def discriminator_model():\n",
    "    optimizer = RMSprop(lr=0.0008, clipvalue=1.0, decay=6e-8)\n",
    "    model = Sequential()\n",
    "    model.add(d)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "dm = discriminator_model()\n",
    "dm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 64, 64, 3)         2750083   \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 1045633   \n",
      "=================================================================\n",
      "Total params: 3,795,716\n",
      "Trainable params: 3,762,564\n",
      "Non-trainable params: 33,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# the trainable adversarial model with binary crossentroy loss and RMS optimizer\n",
    "def adversarial_model():\n",
    "    # we don't train the discriminator when we train the generator\n",
    "    for layer in d.layers:\n",
    "        layer.trainable=False\n",
    "        \n",
    "    optimizer = RMSprop(lr=0.0004, clipvalue=1.0, decay=3e-8)\n",
    "    model = Sequential()\n",
    "    model.add(g)\n",
    "    model.add(d)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "am = adversarial_model()\n",
    "am.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------\n",
    "# Read the dataset\n",
    "#----------------------------------------------------------------------------\n",
    "imgs = []\n",
    "\n",
    "f = []\n",
    "for (dirpath, dirnames, filenames) in walk('pokemon_small'):\n",
    "    f.extend(filenames)\n",
    "\n",
    "for src in f:\n",
    "    #read PNG images and convert them to RGB tensors\n",
    "    # on colab: 'pokemon_small/'\n",
    "    img = mpimg.imread('pokemon_small\\\\' + src)[:,:,0:3]\n",
    "    imgs.append(img)\n",
    "    \n",
    "imgs = np.array(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this version, we train the discriminator and adversarial model separately if the accuracy of one model is much better than the other\n",
    "def train():\n",
    "    trainA, trainD = True, True\n",
    "    for i in range(epochs):    \n",
    "        if (trainD):\n",
    "            imgs_train = imgs[np.random.randint(0,imgs.shape[0], size=batch_size), :, :, :]\n",
    "            noise = np.random.normal(0, 1.0, size=[batch_size, noise_size])\n",
    "            imgs_fake = g.predict(noise)\n",
    "            x = np.concatenate((imgs_train, imgs_fake))\n",
    "            y = np.ones([2*batch_size, 1])\n",
    "            y[batch_size:, :] = 0\n",
    "            d_loss = dm.train_on_batch(x, y)\n",
    "\n",
    "        if (trainA):\n",
    "            y = np.ones([batch_size, 1])\n",
    "            noise = np.random.normal(0, 1.0, size=[batch_size, noise_size])\n",
    "            a_loss = am.train_on_batch(noise, y)\n",
    "        \n",
    "        if (d_loss[1]*0.8 > a_loss[1]):\n",
    "            trainA = True\n",
    "            trainD = False\n",
    "        elif (a_loss[1]*0.8 > d_loss[1]):\n",
    "            trainA = False\n",
    "            trainD = True\n",
    "        else:\n",
    "            trainA = True\n",
    "            trainD = True\n",
    "        \n",
    "        if (i % 50 == 0):\n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "            print(log_mesg)\n",
    "        \n",
    "        if (i % 500 == 0):\n",
    "            am.save_weights(\"model\"+str(i)+\".h5\")\n",
    "            plot_images(fake = True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 16 false images\n",
    "def plot_images(save2file=False, fake=True, samples=16, noise=None, step=0):\n",
    "        filename = 'pokemon.png'\n",
    "        if fake:\n",
    "            if noise is None:\n",
    "                noise = np.random.normal(0, 1.0, size=[batch_size, noise_size])\n",
    "            else:\n",
    "                filename = \"pokemon_%d.png\" % step\n",
    "            images = g.predict(noise)\n",
    "        else:\n",
    "            i = np.random.randint(0, imgs.shape[0], samples)\n",
    "            images = imgs[i, :, :, :]\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for i in range(images.shape[0]):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            image = images[i, :, :, :]\n",
    "            image = np.reshape(image, [64, 64, 3])\n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        if save2file:\n",
    "            plt.savefig(filename)\n",
    "            plt.close('all')\n",
    "        else:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Conda\\envs\\Tensorflow-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "0: [D loss: 0.693070, acc: 0.500000]  [A loss: 1.850720, acc: 0.000000]\n",
      "10: [D loss: 0.580438, acc: 0.625000]  [A loss: 0.186648, acc: 1.000000]\n",
      "20: [D loss: 0.573044, acc: 0.500000]  [A loss: 0.356155, acc: 1.000000]\n",
      "30: [D loss: 1.132400, acc: 0.500000]  [A loss: 0.276926, acc: 1.000000]\n",
      "40: [D loss: 0.556969, acc: 0.998047]  [A loss: 0.313613, acc: 1.000000]\n",
      "50: [D loss: 1.654252, acc: 0.500000]  [A loss: 0.276796, acc: 1.000000]\n",
      "60: [D loss: 0.549655, acc: 0.726562]  [A loss: 0.473727, acc: 1.000000]\n",
      "70: [D loss: 0.308155, acc: 1.000000]  [A loss: 1.079517, acc: 0.000000]\n",
      "80: [D loss: 0.755889, acc: 0.500000]  [A loss: 0.472456, acc: 0.996094]\n",
      "90: [D loss: 0.506479, acc: 0.500000]  [A loss: 0.390913, acc: 1.000000]\n",
      "100: [D loss: 0.786799, acc: 0.476562]  [A loss: 0.241402, acc: 1.000000]\n",
      "110: [D loss: 0.995498, acc: 0.500000]  [A loss: 0.505977, acc: 0.988281]\n",
      "120: [D loss: 0.353703, acc: 0.878906]  [A loss: 0.410997, acc: 1.000000]\n",
      "130: [D loss: 0.193946, acc: 1.000000]  [A loss: 0.883765, acc: 0.011719]\n",
      "140: [D loss: 1.016873, acc: 0.486328]  [A loss: 0.327484, acc: 1.000000]\n",
      "150: [D loss: 0.886354, acc: 0.472656]  [A loss: 0.380702, acc: 0.972656]\n",
      "160: [D loss: 0.174408, acc: 1.000000]  [A loss: 0.992152, acc: 0.003906]\n",
      "170: [D loss: 1.695219, acc: 0.500000]  [A loss: 0.248045, acc: 1.000000]\n",
      "180: [D loss: 0.405010, acc: 0.585938]  [A loss: 0.231084, acc: 1.000000]\n",
      "190: [D loss: 0.223539, acc: 1.000000]  [A loss: 0.979662, acc: 0.000000]\n",
      "200: [D loss: 1.094567, acc: 0.488281]  [A loss: 0.307191, acc: 0.996094]\n",
      "210: [D loss: 0.379514, acc: 0.777344]  [A loss: 0.381786, acc: 0.984375]\n",
      "220: [D loss: 0.236259, acc: 1.000000]  [A loss: 0.993753, acc: 0.050781]\n",
      "230: [D loss: 0.996740, acc: 0.500000]  [A loss: 0.349361, acc: 0.996094]\n",
      "240: [D loss: 0.242835, acc: 0.962891]  [A loss: 0.230526, acc: 0.996094]\n",
      "250: [D loss: 0.121650, acc: 0.990234]  [A loss: 0.073724, acc: 1.000000]\n",
      "260: [D loss: 1.395742, acc: 0.500000]  [A loss: 0.132517, acc: 1.000000]\n",
      "270: [D loss: 0.685873, acc: 0.505859]  [A loss: 0.332088, acc: 1.000000]\n",
      "280: [D loss: 0.327940, acc: 0.941406]  [A loss: 1.571954, acc: 0.003906]\n",
      "290: [D loss: 0.418727, acc: 0.921875]  [A loss: 0.656336, acc: 0.648438]\n",
      "300: [D loss: 0.743658, acc: 0.498047]  [A loss: 0.484669, acc: 0.972656]\n",
      "310: [D loss: 1.512908, acc: 0.494141]  [A loss: 0.212150, acc: 1.000000]\n",
      "320: [D loss: 0.505054, acc: 0.664062]  [A loss: 0.463812, acc: 0.996094]\n",
      "330: [D loss: 0.323891, acc: 0.982422]  [A loss: 0.329636, acc: 1.000000]\n",
      "340: [D loss: 0.812503, acc: 0.533203]  [A loss: 0.187052, acc: 1.000000]\n",
      "350: [D loss: 1.301276, acc: 0.617188]  [A loss: 0.512534, acc: 0.785156]\n",
      "360: [D loss: 0.396849, acc: 0.908203]  [A loss: 1.116352, acc: 0.007812]\n",
      "370: [D loss: 0.541146, acc: 0.677734]  [A loss: 0.433337, acc: 0.996094]\n",
      "380: [D loss: 0.376578, acc: 0.933594]  [A loss: 0.278689, acc: 0.996094]\n",
      "390: [D loss: 1.048071, acc: 0.500000]  [A loss: 0.310721, acc: 1.000000]\n",
      "400: [D loss: 0.654177, acc: 0.644531]  [A loss: 0.310721, acc: 1.000000]\n",
      "410: [D loss: 0.826359, acc: 0.503906]  [A loss: 0.427274, acc: 0.960938]\n",
      "420: [D loss: 0.314724, acc: 0.943359]  [A loss: 2.966469, acc: 0.000000]\n",
      "430: [D loss: 0.376294, acc: 0.867188]  [A loss: 0.141640, acc: 1.000000]\n",
      "440: [D loss: 1.019486, acc: 0.500000]  [A loss: 0.391222, acc: 0.929688]\n",
      "450: [D loss: 0.587723, acc: 0.707031]  [A loss: 0.337769, acc: 0.992188]\n",
      "460: [D loss: 0.807194, acc: 0.509766]  [A loss: 0.384160, acc: 0.890625]\n",
      "470: [D loss: 0.737625, acc: 0.576172]  [A loss: 0.244787, acc: 1.000000]\n",
      "480: [D loss: 0.492111, acc: 0.777344]  [A loss: 0.272714, acc: 1.000000]\n",
      "490: [D loss: 0.532050, acc: 0.816406]  [A loss: 0.729812, acc: 0.386719]\n",
      "500: [D loss: 0.595188, acc: 0.574219]  [A loss: 0.564992, acc: 0.847656]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-791a365e70f7>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0ma_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.8\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0ma_loss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Conda\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Conda\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Conda\\envs\\Tensorflow-GPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Conda\\envs\\Tensorflow-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
